{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Alignment\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from utils import *\n",
    "from natsort import natsorted\n",
    "\n",
    "import argparse\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_descriptors(imGray):\n",
    "    \"\"\"\n",
    "    Calcula keypoints e descritores SIFT para uma imagem em tons de cinza.\n",
    "\n",
    "    Args:\n",
    "        imGray: Uma imagem em tons de cinza representada como um array NumPy.\n",
    "\n",
    "    Returns:\n",
    "        keypoints: Uma lista de keypoints detectados.\n",
    "        descriptors: Um array NumPy contendo os descritores calculados.\n",
    "    \"\"\"\n",
    "\n",
    "    # Cria um objeto SIFT para detecção de keypoints e cálculo de descritores\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    # Detecta keypoints e calcula descritores usando SIFT\n",
    "    keypoints, descriptors = sift.detectAndCompute(imGray, None)\n",
    "\n",
    "    # Imprime o número de keypoints detectados e a forma do array de descritores\n",
    "    print(\"keypoints: {}, descriptors: {}\".format(len(keypoints), descriptors.shape))\n",
    "\n",
    "    return keypoints, descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matcher(trees, checks):\n",
    "    \"\"\"\n",
    "    Cria um objeto cv2.FlannBasedMatcher para correspondência de características.\n",
    "\n",
    "    Args:\n",
    "        trees: Número de árvores na estrutura de dados KD-Tree usada para busca rápida de vizinhos mais próximos.\n",
    "        checks: Número de verificações realizadas durante a busca de correspondências. Aumentar esse valor melhora a precisão, mas também aumenta o tempo de processamento.\n",
    "\n",
    "    Returns:\n",
    "        matcher: Um objeto cv2.FlannBasedMatcher configurado para correspondência de características usando o algoritmo FLANN.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define o tipo de índice como KD-Tree\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "\n",
    "    # Parâmetros para a construção do índice KD-Tree\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=trees)\n",
    "\n",
    "    # Parâmetros para a busca de correspondências\n",
    "    search_params = dict(checks=checks)\n",
    "\n",
    "    # Cria o objeto matcher usando os parâmetros definidos\n",
    "    matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    return matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_good_matches_loc(matcher, keypoints1, descriptors1, keypoints2, descriptors2, factor):\n",
    "    \"\"\"\n",
    "    Encontra correspondências de boa qualidade entre dois conjuntos de keypoints e descritores, e retorna suas localizações.\n",
    "\n",
    "    Args:\n",
    "        matcher: Um objeto cv2.FlannBasedMatcher configurado para correspondência de características.\n",
    "        keypoints1: Uma lista de keypoints da primeira imagem.\n",
    "        descriptors1: Um array NumPy contendo os descritores da primeira imagem.\n",
    "        keypoints2: Uma lista de keypoints da segunda imagem.\n",
    "        descriptors2: Um array NumPy contendo os descritores da segunda imagem.\n",
    "        factor: Um fator de limiar usado para filtrar correspondências ambíguas. Quanto menor o fator, mais rigoroso é o filtro.\n",
    "\n",
    "    Returns:\n",
    "        good_matches: Uma lista de correspondências de boa qualidade entre as duas imagens.\n",
    "        points1: Um array NumPy contendo as coordenadas dos keypoints correspondentes na primeira imagem.\n",
    "        points2: Um array NumPy contendo as coordenadas dos keypoints correspondentes na segunda imagem.\n",
    "    \"\"\"\n",
    "\n",
    "    # Encontra os dois vizinhos mais próximos para cada descritor na primeira imagem\n",
    "    matches = matcher.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "    # Inicializa uma lista para armazenar as boas correspondências\n",
    "    good_matches = []\n",
    "\n",
    "    # Aplica o teste de razão de Lowe para filtrar correspondências ambíguas\n",
    "    for m, n in matches:\n",
    "        if m.distance < factor * n.distance:  # Mantém apenas correspondências onde a distância para o vizinho mais próximo é significativamente menor que a distância para o segundo vizinho mais próximo\n",
    "            good_matches.append(m)\n",
    "\n",
    "    # Extrai as coordenadas dos keypoints correspondentes nas duas imagens\n",
    "    points1 = np.float32([keypoints1[match.queryIdx].pt for match in good_matches]).reshape(-1, 1, 2)\n",
    "    points2 = np.float32([keypoints2[match.trainIdx].pt for match in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    return good_matches, points1, points2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_homography(img1, img2, points1, points2):\n",
    "    \"\"\"\n",
    "    Alinha a imagem 'img1' com a imagem 'img2' usando uma transformação de homografia calculada a partir de pontos correspondentes.\n",
    "\n",
    "    Args:\n",
    "        img1: A imagem a ser alinhada.\n",
    "        img2: A imagem de referência para o alinhamento.\n",
    "        points1: Um array NumPy contendo as coordenadas dos pontos na imagem 'img1'.\n",
    "        points2: Um array NumPy contendo as coordenadas dos pontos correspondentes na imagem 'img2'.\n",
    "\n",
    "    Returns:\n",
    "        aligned_img: A imagem 'img1' alinhada com a imagem 'img2' usando a transformação de homografia.\n",
    "    \"\"\"\n",
    "\n",
    "    # Obtém as dimensões da imagem de referência\n",
    "    height, width, channels = img2.shape\n",
    "\n",
    "    # Calcula a matriz de homografia usando RANSAC para robustez contra outliers\n",
    "    homography, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    "\n",
    "    # Aplica a transformação de perspectiva à imagem 'img1' usando a homografia calculada\n",
    "    aligned_img = cv2.warpPerspective(img1, homography, (width, height))\n",
    "\n",
    "    return aligned_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_im1_to_im2(img1, img2):\n",
    "    \"\"\"\n",
    "    Alinha a imagem 'img1' com a imagem 'img2' usando correspondência de características e homografia.\n",
    "\n",
    "    Args:\n",
    "        img1: A imagem a ser alinhada.\n",
    "        img2: A imagem de referência para o alinhamento.\n",
    "\n",
    "    Returns:\n",
    "        imMatches: Uma imagem mostrando as correspondências encontradas entre as duas imagens.\n",
    "        aligned_img: A imagem 'img1' alinhada com a imagem 'img2'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Converte as imagens para tons de cinza\n",
    "    img1Gray = convert_to_grayscale(img1)\n",
    "    img2Gray = convert_to_grayscale(img2)\n",
    "\n",
    "    # Calcula keypoints e descritores para ambas as imagens\n",
    "    keypoints1, descriptors1 = compute_descriptors(img1Gray)\n",
    "    keypoints2, descriptors2 = compute_descriptors(img2Gray)\n",
    "\n",
    "    # Cria um objeto matcher para correspondência de características\n",
    "    matcher = create_matcher(trees=5, checks=50)\n",
    "\n",
    "    # Encontra correspondências de boa qualidade e suas localizações\n",
    "    good_matches, points1, points2 = find_good_matches_loc(matcher, keypoints1, descriptors1, keypoints2, descriptors2, factor=0.80)\n",
    "\n",
    "    # Desenha as correspondências encontradas em uma imagem\n",
    "    imMatches = cv2.drawMatches(img1, keypoints1, img2, keypoints2, good_matches, None, flags=2)\n",
    "\n",
    "    # Aplica a homografia para alinhar a imagem 'img2' com a imagem 'img1'\n",
    "    aligned_img = apply_homography(img2, img1, points2, points1)\n",
    "\n",
    "    return imMatches, aligned_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main(img_path, save_path, match_path):\n",
    "    \"\"\"\n",
    "    Função principal que realiza o alinhamento de imagens em sequência.\n",
    "\n",
    "    Args:\n",
    "        img_path: O caminho da pasta contendo as imagens a serem alinhadas.\n",
    "        save_path: O caminho da pasta onde as imagens alinhadas serão salvas.\n",
    "        match_path: O caminho da pasta onde as imagens com as correspondências serão salvas\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Encontra todos os arquivos na pasta de imagens e os ordena naturalmente\n",
    "    all_files = find_all_files(img_path)\n",
    "    all_files = natsorted(all_files)\n",
    "    print(all_files)\n",
    "    \n",
    "    aligned_img_list = []\n",
    "    aligned_img_list.append(read_image(img_path + all_files[0]))\n",
    "    \n",
    "    # Itera sobre os arquivos, alinhando cada imagem com a próxima na sequência\n",
    "    for i in range(len(all_files)-1):\n",
    "        # Define os caminhos das imagens de origem e destino\n",
    "        source_img_path = img_path + all_files[i]\n",
    "        target_img_path = img_path + all_files[i+1]\n",
    "        #source_img_path = img_path + all_files[0]\n",
    "        #target_img_path = img_path + all_files[i]\n",
    "\n",
    "        # Define os nomes dos arquivos de saída para as correspondências e a imagem alinhada\n",
    "        match_save_as = \"matches_\" + str(i) + \".jpg\" \n",
    "        align_save_as = \"align_\" + str(i) + \".jpg\"\n",
    "\n",
    "        # Lê a imagem de origem\n",
    "        print(\"Reading a source image : \", source_img_path)\n",
    "        source_img = read_image(source_img_path)\n",
    "\n",
    "        # Lê a imagem de destino\n",
    "        print(\"Reading a target image : \", target_img_path);\n",
    "        target_img = read_image(target_img_path)\n",
    "\n",
    "        # Alinha as imagens\n",
    "        print(\"Aligning images ...\")\n",
    "        #imMatches, aligned_img = align_im1_to_im2(source_img, target_img)\n",
    "        imMatches, aligned_img = align_im1_to_im2(aligned_img_list[i], target_img)\n",
    "        \n",
    "        aligned_img_list.append(aligned_img)\n",
    "        \n",
    "        # Salva a imagem com as correspondências\n",
    "        print(\"Saving an feature matching image : \", save_path);\n",
    "        save_image(match_path, match_save_as, imMatches)\n",
    "\n",
    "        # Salva a imagem alinhada\n",
    "        print(\"Saving an aligned image : \", save_path);\n",
    "        save_image(save_path, align_save_as, aligned_img)\n",
    "\n",
    "        # Adiciona uma linha em branco para separar a saída de cada iteração\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main(img_path, save_path, match_path):\n",
    "    \"\"\"\n",
    "    Função principal que realiza o alinhamento de imagens em sequência.\n",
    "\n",
    "    Args:\n",
    "        img_path: O caminho da pasta contendo as imagens a serem alinhadas.\n",
    "        save_path: O caminho da pasta onde as imagens alinhadas serão salvas.\n",
    "        match_path: O caminho da pasta onde as imagens com as correspondências serão salvas\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Encontra todos os arquivos na pasta de imagens e os ordena naturalmente\n",
    "    all_files = find_all_files(img_path)\n",
    "    all_files = natsorted(all_files)\n",
    "    print(all_files)\n",
    "    \n",
    "    #aligned_img_list = []\n",
    "    #aligned_img_list.append(read_image(img_path + all_files[0]))\n",
    "\n",
    "    aligned_img = read_image(img_path + all_files[0])\n",
    "\n",
    "    # Itera sobre os arquivos, alinhando cada imagem com a próxima na sequência\n",
    "    for i in range(len(all_files)-1):\n",
    "        # Define os caminhos das imagens de origem e destino\n",
    "        source_img_path = img_path + all_files[i]\n",
    "        target_img_path = img_path + all_files[i+1]\n",
    "        #source_img_path = img_path + all_files[0]\n",
    "        #target_img_path = img_path + all_files[i]\n",
    "\n",
    "        # Define os nomes dos arquivos de saída para as correspondências e a imagem alinhada\n",
    "        match_save_as = \"matches_\" + str(i) + \".jpg\" \n",
    "        align_save_as = \"align_\" + str(i) + \".jpg\"\n",
    "\n",
    "        # Lê a imagem de origem\n",
    "        print(\"Reading a source image : \", source_img_path)\n",
    "        source_img = read_image(source_img_path)\n",
    "\n",
    "        # Lê a imagem de destino\n",
    "        print(\"Reading a target image : \", target_img_path);\n",
    "        target_img = read_image(target_img_path)\n",
    "\n",
    "        # Alinha as imagens\n",
    "        print(\"Aligning images ...\")\n",
    "        #imMatches, aligned_img = align_im1_to_im2(source_img, target_img)\n",
    "        imMatches, aligned_img = align_im1_to_im2(aligned_img, target_img)\n",
    "        \n",
    "        #aligned_img_list.append(aligned_img)\n",
    "        \n",
    "        # Salva a imagem com as correspondências\n",
    "        print(\"Saving an feature matching image : \", save_path);\n",
    "        save_image(match_path, match_save_as, imMatches)\n",
    "\n",
    "        # Salva a imagem alinhada\n",
    "        print(\"Saving an aligned image : \", save_path);\n",
    "        save_image(save_path, align_save_as, aligned_img)\n",
    "\n",
    "        # Adiciona uma linha em branco para separar a saída de cada iteração\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frame_00000.jpg', 'frame_00001.jpg', 'frame_00002.jpg', 'frame_00003.jpg', 'frame_00004.jpg', 'frame_00005.jpg', 'frame_00006.jpg', 'frame_00007.jpg', 'frame_00008.jpg', 'frame_00009.jpg', 'frame_00010.jpg', 'frame_00011.jpg', 'frame_00012.jpg', 'frame_00013.jpg', 'frame_00014.jpg', 'frame_00015.jpg', 'frame_00016.jpg', 'frame_00017.jpg', 'frame_00018.jpg', 'frame_00019.jpg', 'frame_00020.jpg', 'frame_00021.jpg', 'frame_00022.jpg', 'frame_00023.jpg', 'frame_00024.jpg', 'frame_00025.jpg', 'frame_00026.jpg', 'frame_00027.jpg', 'frame_00028.jpg', 'frame_00029.jpg']\n"
     ]
    }
   ],
   "source": [
    "img_path = '/home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/'\n",
    "save_path = '/home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/'\n",
    "match_save_path = '/home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/match_save_3/'    \n",
    "\n",
    "all_files = find_all_files(img_path)\n",
    "all_files = natsorted(all_files)\n",
    "print(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frame_00000.jpg', 'frame_00001.jpg', 'frame_00002.jpg', 'frame_00003.jpg', 'frame_00004.jpg', 'frame_00005.jpg', 'frame_00006.jpg', 'frame_00007.jpg', 'frame_00008.jpg', 'frame_00009.jpg', 'frame_00010.jpg', 'frame_00011.jpg', 'frame_00012.jpg', 'frame_00013.jpg', 'frame_00014.jpg', 'frame_00015.jpg', 'frame_00016.jpg', 'frame_00017.jpg', 'frame_00018.jpg', 'frame_00019.jpg', 'frame_00020.jpg', 'frame_00021.jpg', 'frame_00022.jpg', 'frame_00023.jpg', 'frame_00024.jpg', 'frame_00025.jpg', 'frame_00026.jpg', 'frame_00027.jpg', 'frame_00028.jpg', 'frame_00029.jpg']\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00000.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00001.jpg\n",
      "Aligning images ...\n",
      "keypoints: 39, descriptors: (39, 128)\n",
      "keypoints: 42, descriptors: (42, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00001.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00002.jpg\n",
      "Aligning images ...\n",
      "keypoints: 41, descriptors: (41, 128)\n",
      "keypoints: 46, descriptors: (46, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00002.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00003.jpg\n",
      "Aligning images ...\n",
      "keypoints: 55, descriptors: (55, 128)\n",
      "keypoints: 50, descriptors: (50, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00003.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00004.jpg\n",
      "Aligning images ...\n",
      "keypoints: 70, descriptors: (70, 128)\n",
      "keypoints: 53, descriptors: (53, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00004.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00005.jpg\n",
      "Aligning images ...\n",
      "keypoints: 64, descriptors: (64, 128)\n",
      "keypoints: 66, descriptors: (66, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00005.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00006.jpg\n",
      "Aligning images ...\n",
      "keypoints: 83, descriptors: (83, 128)\n",
      "keypoints: 65, descriptors: (65, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00006.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00007.jpg\n",
      "Aligning images ...\n",
      "keypoints: 101, descriptors: (101, 128)\n",
      "keypoints: 71, descriptors: (71, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00007.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00008.jpg\n",
      "Aligning images ...\n",
      "keypoints: 105, descriptors: (105, 128)\n",
      "keypoints: 88, descriptors: (88, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00008.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00009.jpg\n",
      "Aligning images ...\n",
      "keypoints: 122, descriptors: (122, 128)\n",
      "keypoints: 97, descriptors: (97, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00009.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00010.jpg\n",
      "Aligning images ...\n",
      "keypoints: 131, descriptors: (131, 128)\n",
      "keypoints: 97, descriptors: (97, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00010.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00011.jpg\n",
      "Aligning images ...\n",
      "keypoints: 149, descriptors: (149, 128)\n",
      "keypoints: 113, descriptors: (113, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00011.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00012.jpg\n",
      "Aligning images ...\n",
      "keypoints: 149, descriptors: (149, 128)\n",
      "keypoints: 134, descriptors: (134, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00012.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00013.jpg\n",
      "Aligning images ...\n",
      "keypoints: 169, descriptors: (169, 128)\n",
      "keypoints: 144, descriptors: (144, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00013.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00014.jpg\n",
      "Aligning images ...\n",
      "keypoints: 192, descriptors: (192, 128)\n",
      "keypoints: 165, descriptors: (165, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00014.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00015.jpg\n",
      "Aligning images ...\n",
      "keypoints: 187, descriptors: (187, 128)\n",
      "keypoints: 172, descriptors: (172, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00015.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00016.jpg\n",
      "Aligning images ...\n",
      "keypoints: 204, descriptors: (204, 128)\n",
      "keypoints: 202, descriptors: (202, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00016.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00017.jpg\n",
      "Aligning images ...\n",
      "keypoints: 241, descriptors: (241, 128)\n",
      "keypoints: 229, descriptors: (229, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00017.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00018.jpg\n",
      "Aligning images ...\n",
      "keypoints: 294, descriptors: (294, 128)\n",
      "keypoints: 290, descriptors: (290, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00018.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00019.jpg\n",
      "Aligning images ...\n",
      "keypoints: 310, descriptors: (310, 128)\n",
      "keypoints: 344, descriptors: (344, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00019.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00020.jpg\n",
      "Aligning images ...\n",
      "keypoints: 384, descriptors: (384, 128)\n",
      "keypoints: 438, descriptors: (438, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00020.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00021.jpg\n",
      "Aligning images ...\n",
      "keypoints: 469, descriptors: (469, 128)\n",
      "keypoints: 529, descriptors: (529, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00021.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00022.jpg\n",
      "Aligning images ...\n",
      "keypoints: 545, descriptors: (545, 128)\n",
      "keypoints: 615, descriptors: (615, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00022.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00023.jpg\n",
      "Aligning images ...\n",
      "keypoints: 662, descriptors: (662, 128)\n",
      "keypoints: 641, descriptors: (641, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00023.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00024.jpg\n",
      "Aligning images ...\n",
      "keypoints: 701, descriptors: (701, 128)\n",
      "keypoints: 704, descriptors: (704, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00024.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00025.jpg\n",
      "Aligning images ...\n",
      "keypoints: 729, descriptors: (729, 128)\n",
      "keypoints: 744, descriptors: (744, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00025.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00026.jpg\n",
      "Aligning images ...\n",
      "keypoints: 765, descriptors: (765, 128)\n",
      "keypoints: 814, descriptors: (814, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00026.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00027.jpg\n",
      "Aligning images ...\n",
      "keypoints: 792, descriptors: (792, 128)\n",
      "keypoints: 914, descriptors: (914, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00027.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00028.jpg\n",
      "Aligning images ...\n",
      "keypoints: 891, descriptors: (891, 128)\n",
      "keypoints: 930, descriptors: (930, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n",
      "Reading a source image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00028.jpg\n",
      "Reading a target image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/input/frame_00029.jpg\n",
      "Aligning images ...\n",
      "keypoints: 931, descriptors: (931, 128)\n",
      "keypoints: 988, descriptors: (988, 128)\n",
      "Saving an feature matching image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "Saving an aligned image :  /home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main(img_path, save_path, match_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deph from focus\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pygco import cut_simple\n",
    "from utils import *\n",
    "from natsort import natsorted\n",
    "\n",
    "\n",
    "import argparse\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focus_stack(aligned_img, gaussian_size, laplacian_size):\n",
    "    imGray = convert_to_grayscale(aligned_img)\n",
    "    gaussian_img = cv2.GaussianBlur(imGray, (gaussian_size, gaussian_size), 0)\n",
    "    laplacian_img = cv2.Laplacian(gaussian_img, cv2.CV_64F, ksize=laplacian_size)\n",
    "    \n",
    "    return laplacian_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focus_stack_canny(aligned_img, gaussian_size, canny_threshold1, canny_threshold2):\n",
    "    # Converte a imagem para escala de cinza\n",
    "    imGray = convert_to_grayscale(aligned_img)\n",
    "    \n",
    "    # Aplica o filtro Gaussiano para suavizar a imagem\n",
    "    gaussian_img = cv2.GaussianBlur(imGray, (gaussian_size, gaussian_size), 0)\n",
    "    \n",
    "    # Aplica a detecção de bordas usando o algoritmo Canny\n",
    "    canny_img = cv2.Canny(gaussian_img, canny_threshold1, canny_threshold2)\n",
    "    \n",
    "    return canny_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focus_measure_cal(cost_volume, kernel_size=9):\n",
    "    focus_measure = np.zeros_like(cost_volume)\n",
    "    kernel = np.ones((kernel_size, kernel_size))\n",
    "\n",
    "    for i in range(len(cost_volume)):\n",
    "        focus_img = cost_volume[i]\n",
    "        focus_measure[i] = focus_img*focus_img\n",
    "        focus_measure[i] = cv2.filter2D(focus_measure[i], -1, kernel)\n",
    "        \n",
    "    return focus_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_in_focus(img_list, cost_volume, kernel_size, gaussian_size):\n",
    "    bgr_imgs = np.asarray(img_list)\n",
    "    \n",
    "    all_in_focus_img = np.zeros_like(bgr_imgs[0])\n",
    "    height, width, channels = all_in_focus_img.shape\n",
    "    \n",
    "    focus_measure = focus_measure_cal(cost_volume, kernel_size)\n",
    "    argmax = np.argmax(focus_measure, axis=0)\n",
    "    \n",
    "    normalized = 255 - (normalize(argmax) * 255)\n",
    "    depth_map = cv2.GaussianBlur(normalized, (gaussian_size, gaussian_size), 0)\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            idx = argmax[i, j]\n",
    "            all_in_focus_img[i, j, :] = bgr_imgs[idx, i, j, :]\n",
    "    \n",
    "    return depth_map, all_in_focus_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def graph_cut(cost_volume, unary_scale, pair_scale, n_iter):\n",
    "    n = len(cost_volume)\n",
    "    ii, jj = np.meshgrid(range(n), range(n))\n",
    "    \n",
    "    unary_cost = normalize(np.stack(cost_volume, axis=-1)) * unary_scale\n",
    "    pairwise_cost = np.abs(ii - jj) * pair_scale\n",
    "\n",
    "    graph_img = cut_simple(unary_cost.astype(np.int32), pairwise_cost.astype(np.int32), n_iter)\n",
    "\n",
    "    return graph_img\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(base_path):\n",
    "    #img_path = base_path + \"align/\"\n",
    "    img_path = base_path\n",
    "    focus_save_path  = base_path + \"focus_stack/\"\n",
    "    depth_save_path = base_path + \"depth_map/\"\n",
    "    all_focus_save_path = base_path + \"all_in_focus/\"\n",
    "    graph_save_path = base_path + \"graph_cut/\"\n",
    "    wmf_save_path = base_path + \"wmf/\"\n",
    "    save_as = \"output.jpg\"\n",
    "    \n",
    "    img_list = read_images_from_path(img_path)\n",
    "    print(img_list)\n",
    "    #img_list = natsorted(img_list)\n",
    "    stacked_focus_imgs = []\n",
    "    \n",
    "    print(\"Stacking focus using LoG ... \")\n",
    "    for i, aligned_img in enumerate(img_list):\n",
    "        focus_save_as = \"focus_\" + str(i) + \".jpg\"\n",
    "        \n",
    "        laplacian_img = focus_stack(aligned_img, gaussian_size=5, laplacian_size=5)\n",
    "        #canny_img = focus_stack_canny(aligned_img, gaussian_size=5, canny_threshold1=10, canny_threshold2=50)\n",
    "\n",
    "        stacked_focus_imgs.append(laplacian_img)\n",
    "        #stacked_focus_imgs.append(canny_img)\n",
    "        \n",
    "        print(\"... Saving images ...\")\n",
    "        save_image(focus_save_path, focus_save_as, laplacian_img)\n",
    "        #save_image(focus_save_path, focus_save_as, canny_img)\n",
    "        \n",
    "    cost_volume = np.asarray(stacked_focus_imgs)\n",
    "    \n",
    "    print(\"Extracting focus from each images ...\")\n",
    "    depth_map, all_in_focus_img = all_in_focus(img_list, cost_volume, kernel_size=64, gaussian_size=5)\n",
    "    print(\"Saving depth-from-focus image : \", depth_save_path)\n",
    "    save_image(depth_save_path, save_as, depth_map)\n",
    "    print(\"Saving all-in-focus image : \", all_focus_save_path)\n",
    "    save_image(all_focus_save_path, save_as, all_in_focus_img)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/lelis/Documents/Projetos/Stereo_Multifocus/depth_from_focus/data/obj_2/output_3/'\n",
    "main(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depth_from_focus_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
